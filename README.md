# DocMind

**DocMind** is an openâ€‘source, productionâ€‘oriented **multimodal document intelligence platform**.

It enables you to ingest complex PDF documents, extract **text, images, and tables**, store them in a **vector database**, and interact with the content through a **multimodal RAG (Retrievalâ€‘Augmented Generation) chat interface**.

DocMind is designed with **real deployment and extensibility** in mind rather than as a toy demo or oneâ€‘off experiment.

---

## Why DocMind

Most existing â€œChat with PDFâ€ projects focus on quick demos:

* Textâ€‘only RAG
* Singleâ€‘file scripts
* Tight coupling to one LLM provider
* Limited extensibility

**DocMind is different.**

It focuses on:

* ğŸ§  **Multimodal understanding** (text + figures + tables)
* ğŸ—ï¸ **Clean system architecture** suitable for production
* ğŸ”Œ **Pluggable LLM / embedding backends**
* ğŸ“¦ **Endâ€‘toâ€‘end pipeline** from document ingestion to chat UI

---

## Core Features

* **Document Ingestion Pipeline**

  * PDF parsing with Docling
  * Text chunking for vector storage
  * Image extraction with metadata
  * Table extraction (structured data + rendered images)

* **Vectorâ€‘based Retrieval**

  * PostgreSQL + pgvector
  * Metadataâ€‘aware similarity search
  * Image / table references preserved in retrieval

* **Multimodal RAG Chat**

  * Text answers grounded in document context
  * Related images and tables returned with answers
  * Multiâ€‘turn conversation support

* **Productionâ€‘Ready Architecture**

  * Clear service boundaries
  * Async backend (FastAPI)
  * Dockerized infrastructure

---

## System Architecture

```
Frontend (Next.js)
   â”‚
   â–¼
Backend API (FastAPI)
   â”‚
   â”œâ”€â”€ Document Ingestion Pipeline
   â”‚     â”œâ”€â”€ PDF Parsing (Docling)
   â”‚     â”œâ”€â”€ Text Chunking
   â”‚     â”œâ”€â”€ Image / Table Extraction
   â”‚
   â”œâ”€â”€ Retrieval Layer
   â”‚     â””â”€â”€ PostgreSQL + pgvector
   â”‚
   â””â”€â”€ RAG Engine
         â”œâ”€â”€ Context Retrieval
         â”œâ”€â”€ Multimodal Prompting
         â””â”€â”€ LLM Response Generation
```

---

## Tech Stack

### Backend

* **Framework**: FastAPI
* **PDF Processing**: Docling
* **Vector Store**: PostgreSQL + pgvector
* **Embeddings**: OpenAI / HuggingFace (pluggable)
* **LLM Providers**: OpenAI, Ollama (pluggable)
* **Cache / Queue**: Redis (optional)

### Frontend

* **Framework**: Next.js (App Router)
* **Styling**: TailwindCSS
* **UI Components**: shadcn/ui

### Infrastructure

* Docker & Docker Compose
* PostgreSQL 15
* Redis

---

## Getting Started

### Prerequisites

* Docker & Docker Compose
* Node.js 18+
* Python 3.11+

(Optional)

* OpenAI API Key **or** Ollama (local LLM)

---

### Quick Start

```bash
# Clone repository
git clone https://github.com/yourname/docmind.git
cd docmind

# Environment setup
cp .env.example .env

# Start services
docker-compose up -d
```

Access:

* Frontend: [http://localhost:3000](http://localhost:3000)
* Backend API: [http://localhost:8000](http://localhost:8000)
* API Docs: [http://localhost:8000/docs](http://localhost:8000/docs)

---

## Example Use Case

DocMind is wellâ€‘suited for:

* Technical papers and research PDFs
* Product documentation
* Educational materials
* Reports with figures and tables

For demonstration, you can use the paper **â€œAttention Is All You Needâ€** to verify:

* Textâ€‘based Q&A
* Architecture diagram retrieval
* Tableâ€‘based performance comparison
* Multiâ€‘turn contextual conversations

---

## Project Structure (Simplified)

```
backend/
  app/
    pipelines/        # Document ingestion pipeline
    retrieval/        # Vector search & storage
    rag/              # RAG & chat logic
    llm/              # LLM adapters
    embeddings/       # Embedding adapters
frontend/
  app/                # Next.js App Router
```

---

## Design Principles

* **Production first**: engineering clarity over quick demos
* **Extensible by design**: swap LLMs, embeddings, or storage
* **Multimodal by default**: images and tables are firstâ€‘class citizens
* **Transparent retrieval**: sources are traceable

---

## Roadmap

* [ ] OCR support for scanned PDFs
* [ ] Multiâ€‘document crossâ€‘search
* [ ] Streaming / realâ€‘time chat
* [ ] Plugin system for custom processors
* [ ] Roleâ€‘based access & permissions

---

## License

MIT License

---

## Author

Maintained by a single engineer with a focus on **production-grade AI systems**, multimodal RAG, and scalable architecture.

Contributions and discussions are welcome.
